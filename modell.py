import torch
import torch.nn as nn

# usePathwaydata,
class PASNet(nn.Module):
    def __init__(self,usePathwaydata, In_Nodes, Pathway_Nodes, Hidden_Nodes, Out_Nodes, Pathway_Mask):
        super(PASNet, self).__init__()
        # costum var for forward
        self.usePathwaydata = usePathwaydata
        self.sigmoid = nn.Sigmoid()
        self.softmax = nn.Softmax(dim=1)
        self.pathway_mask = Pathway_Mask
        ###gene layer --> pathway layer
        self.sc1 = nn.Linear(In_Nodes, Pathway_Nodes)
        ###pathway layer --> hidden layer
        self.sc2 = nn.Linear(Pathway_Nodes, Hidden_Nodes)
        ###hidden layer --> Output layer
        self.sc3 = nn.Linear(Hidden_Nodes, Out_Nodes)

        # instead
        # self.sc3 = nn.Linear(Pathway_Nodes, Out_Nodes)  # deleted hidden layer y new
        ###randomly select a small sub-network
        self.do_m1 = torch.ones(Pathway_Nodes)
        self.do_m2 = torch.ones(Hidden_Nodes)
        ###if gpu is being used
        if torch.cuda.is_available():
            self.do_m1 = self.do_m1.cuda()
            self.do_m2 = self.do_m2.cuda()

    def forward(self, x):
        ###force the connections between gene layer and pathway layer w.r.t. 'pathway_mask'
        if self.usePathwaydata:
            self.sc1.weight.data = self.sc1.weight.data.mul(self.pathway_mask)
        x = self.sigmoid(self.sc1(x))
        if self.training == True:  ###construct a small sub-network for training only
            x = x.mul(self.do_m1)
        x = self.sigmoid(self.sc2(x))
        if self.training == True:  ###construct a small sub-network for training only y
            x = x.mul(self.do_m2)
        x = self.softmax(self.sc3(x))  # all rows add up to 1

        return x
